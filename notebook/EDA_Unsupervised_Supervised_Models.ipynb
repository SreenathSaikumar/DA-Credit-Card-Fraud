{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"id":"dtHnVBAhLxeY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/creditcardfraud/creditcard.csv')","metadata":{"id":"gzstuMoqMDBq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{"id":"NVhpPBmqN3Zs","outputId":"9ebaa746-1a67-40e9-ed85-5b8f40f79465","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns\n","metadata":{"id":"fBmzK6zeN7x5","outputId":"f077fb9f-d717-429b-e47e-7eea35833cf6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Due to confidentiality issues, the original features and background information about the data is not provided.\nFeatures V1, V2, â€¦ V28 are the principal components obtained with PCA","metadata":{"id":"BkdyI5fqm7OL"}},{"cell_type":"code","source":"df.shape","metadata":{"id":"odRc6JqBN-UM","outputId":"e505b70a-ec27-4bb1-c3da-2588f70b331c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 284807 rows and 31 features","metadata":{"id":"DbBhgv2iY1fQ"}},{"cell_type":"code","source":"df.info()","metadata":{"id":"c7agL5tn3cyb","outputId":"3511d2ce-651f-47b1-fdec-63b27b258061","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"id":"yWmWa40cOHWW","outputId":"b0ec4569-06fe-4680-dfe6-3e76b7122d0a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.hist(figsize = (20, 20))\nplt.show()","metadata":{"id":"dxmKV8hir2Wt","outputId":"8ac9701a-1db0-41a4-bdd4-f12a3c851e6b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# analysing the fraud and not_fraud cases separately\nprint(\"Valid Transactions:\")\ndf.Time[df.Class==0].describe()\n","metadata":{"id":"zxlwXen8dGzI","outputId":"bfb89b49-e0d6-47e3-9ffa-b1ef45589be1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Amount[df.Class==0].describe()","metadata":{"id":"qTg6QJE6X3vF","outputId":"1c105ba6-e654-41c6-ae61-3d1e628632be","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Fraudelent Transactions:\")\ndf.Time[df.Class==1].describe()","metadata":{"id":"JfYKljBxeYSN","outputId":"7b5c0a9e-6f91-4211-8799-f59d16b94e04","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can notice that the number of fraud cases is very few compared to the number of valid transactions which portrays that it is an imbalanced dataset. ","metadata":{"id":"Cyr34pyT392p"}},{"cell_type":"code","source":"df.Amount[df.Class==1].describe()","metadata":{"id":"jcojHxXwX-dU","outputId":"6ab0fb69-8300-4f6f-f6b7-cfe709e361a0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can also notice that the min for fraudelent transaction amount is 0 and for valid, its 406. And most of the fraud cases' amounts tend to be lower than that of valid transactions. Even the max amount of frauds is only 2125 whereas for valid its 25691.\nWe can see in the below graph too that it is clearly a skewed distribution.  ","metadata":{"id":"uhtMZkZJYJF-"}},{"cell_type":"code","source":"colors = [\"green\", \"red\"]\nsns.countplot('Class', data=df, palette=colors)\nplt.title('Frequency of fraud and valid transactions', fontsize=14)","metadata":{"id":"W9gcRioYLpjT","outputId":"e0dfda03-b4b4-4891-9a3f-8dae053886ac","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#OUTLIERS\n#FINDING IQR\nQ1=df.quantile(0.25)\nQ3=df.quantile(0.75)\nIQR=Q3-Q1\n#COUNTING OUTLIERS IN THE ENTIRE DATASET\nprint(\"Count of outliers in the dataset=\",((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).sum().sum())","metadata":{"id":"RnHNvu0cgZyE","outputId":"b3e1e2fb-0303-4d1b-a372-07ad1db5f933","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fraud = df[df['Class'] == 1]\nnot_fraud = df[df['Class'] == 0]\nfraud_perc=(len(fraud)/len(df))*100\nfraud_perc","metadata":{"id":"uX8UfV94OHby","outputId":"8409ed7e-50ee-4374-e4b1-4cf318f0107b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seconds=3600\nplt.figure(figsize=(15,10))\nplt.scatter((not_fraud.Time/(seconds)), not_fraud.Amount, alpha=0.6, label='Not_Fraud')\nplt.scatter((fraud.Time/(seconds)), fraud.Amount, alpha=0.9, label='Fraud')\nplt.title(\"Transaction amount per hour\")\nplt.xlabel(\"Transaction time \")\nplt.ylabel('Amount (USD)')\nplt.legend(loc='upper left')\nplt.show()","metadata":{"id":"9_tLGM-5HaoZ","outputId":"93d95ce2-b9bc-4bb8-91e2-6665112775aa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that most of the frauds have a lower amount than valid transactions","metadata":{"id":"xlujrAixbSUp"}},{"cell_type":"code","source":"df.corr(method=\"pearson\").head(10)","metadata":{"id":"2E1whR2-gdqO","outputId":"315e7305-c0e7-4a3b-e2bc-90abbab8f1d2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corrmat = df.corr()\nfig = plt.figure(figsize = (12, 9))\nsns.heatmap(corrmat, vmax = .8, square = True)\nplt.show()","metadata":{"id":"2p3lwX3FsGHb","outputId":"5c117e93-9b0c-419e-ce98-0efb8b556cca","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Unsupervised Algorithms","metadata":{"id":"L_2h_YsEL9ay"}},{"cell_type":"markdown","source":"Local Outlier Factor","metadata":{"id":"1_6NByz2MFHx"}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.neighbors import LocalOutlierFactor\nx1= df.drop('Class',axis = 1) \ny1= df['Class'] \noutlier_frac=len(fraud)/float(len(not_fraud))\nlof=LocalOutlierFactor(n_neighbors = 20,contamination = outlier_frac)\ny_pred1 = lof.fit_predict(x1)\ny_pred1[y_pred1 == 1] = 0\ny_pred1[y_pred1 == -1] = 1\nn_errors = (y_pred1 != y1).sum()\nprint('LOCAL OUTLIER FACTOR: {}'.format(n_errors))\nprint('Accuracy:',accuracy_score(y1, y_pred1))\nprint('Classification report')\nprint(classification_report(y1, y_pred1))","metadata":{"id":"qQNOIokaMI05","outputId":"40d8c328-6a2c-4ca5-f0fb-ed629ea08623","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Isolation Forest","metadata":{"id":"AwxOJ7fvMP3m"}},{"cell_type":"code","source":"from sklearn.ensemble import IsolationForest\nifor=IsolationForest(max_samples=len(x1),contamination=outlier_frac,random_state=1)\nifor.fit(x1)\nifor_scores = ifor.decision_function(x1)\ny_pred2 = ifor.predict(x1)\ny_pred2[y_pred2 == 1] = 0\ny_pred2[y_pred2 == -1] = 1\nn_errors = (y_pred2 != y1).sum()\nprint('ISOLATION FOREST: {}'.format(n_errors))\nprint('Accuracy:',accuracy_score(y1, y_pred2))\nprint('Classification report')\nprint(classification_report(y1, y_pred2))","metadata":{"id":"SbPBXvJ7MS3j","outputId":"0b3fa880-b2c3-47ce-c982-b3755d0b16c5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Supervised Algorithms","metadata":{"id":"HA194FzUNj9-"}},{"cell_type":"markdown","source":"Credit Card Fraud Detection using Random **Forest**","metadata":{"id":"5gOIRFdFdePe"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix, f1_score, classification_report, balanced_accuracy_score\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, KFold\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_absolute_error\nimport joblib\nfrom sklearn.preprocessing import StandardScaler\nfrom imblearn.over_sampling import SMOTE\n","metadata":{"id":"dyldcpCHejDe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Amount']=StandardScaler().fit_transform(np.array(df['Amount']).reshape(-1, 1))\ndf=df.drop(['Time'],axis=1)\nprint(df.head())\ndf_non_fraud=df[df['Class']==0]\ndf_fraud=df[df['Class']==1]\nprint(df_non_fraud.shape)\nprint(df_fraud.shape)","metadata":{"id":"CMMDkvVeeyth","outputId":"4de55606-89f0-4690-9f91-f82d76710108","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=df[df.columns[:-1]]\ny=df[df.columns[-1]]","metadata":{"id":"ZGCpsIX_eLP2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\nsmote=SMOTE(random_state=42)\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)\nx_train_ov,y_train_ov=smote.fit_resample(x_train,y_train)\nprint(x_train_ov.shape)\nprint(y_train_ov.shape)","metadata":{"id":"IwvpkeYzdRVn","outputId":"d4d67ae7-8c7e-4f0a-d522-094acef3773e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train_ov.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n# random forest model creation\nrfc = RandomForestClassifier()\nrfc.fit(x_train_ov,y_train_ov)\n# predictions\ny_pred = rfc.predict(x_test)","metadata":{"id":"cyc3Dx5DfAOV","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluating the classifier\n#printing every score of the classifier\n#scoring in any thing\nfrom sklearn.metrics import classification_report, accuracy_score,precision_score,recall_score,f1_score,matthews_corrcoef\nfrom sklearn.metrics import confusion_matrix\n# n_outliers = len(Fraud)\n# n_errors = (y_pred != Y_test).sum()\nprint(\"The model used is Random Forest classifier\")\nacc= accuracy_score(y_pred,y_test)\nprint(\"The accuracy is  {}\".format(acc))\nprec= precision_score(y_test,y_pred)\nprint(\"The precision is {}\".format(prec))\nrec= recall_score(y_test,y_pred)\nprint(\"The recall is {}\".format(rec))\nf1= f1_score(y_test,y_pred)\nprint(\"The F1-Score is {}\".format(f1))\nMCC=matthews_corrcoef(y_test,y_pred)\nprint(\"The Matthews correlation coefficient is {}\".format(MCC))\n\n\n#printing the confusion matrix\nLABELS = ['Normal', 'Fraud']\nconf_matrix = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(12, 12))\nsns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\nplt.title(\"Confusion matrix\")\nplt.ylabel('True class')\nplt.xlabel('Predicted class')\nplt.show()\n\n# Run classification metrics\n# plt.figure(figsize=(9, 7))\n# print('{}: {}'.format(\"Random Forest\", n_errors))\n# print(accuracy_score(Y_test, y_pred))\n# print(classification_report(Y_test, y_pred))","metadata":{"id":"6WDwGA-UkYue","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Credit Card Fraud Detection using **SVM**","metadata":{"id":"pWB8CIL-2CEJ"}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn import svm\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score, precision_recall_curve\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc, average_precision_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom mlxtend.plotting import plot_confusion_matrix\nimport itertools","metadata":{"id":"RlEcEHfQ2H9H","execution":{"iopub.status.busy":"2021-12-06T07:56:19.203255Z","iopub.execute_input":"2021-12-06T07:56:19.20363Z","iopub.status.idle":"2021-12-06T07:56:19.670786Z","shell.execute_reply.started":"2021-12-06T07:56:19.203506Z","shell.execute_reply":"2021-12-06T07:56:19.669866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/creditcardfraud/creditcard.csv') # Reading the file .csv\ndf = pd.DataFrame(data) # Converting data to Panda DataFrame","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:56:19.672651Z","iopub.execute_input":"2021-12-06T07:56:19.672916Z","iopub.status.idle":"2021-12-06T07:56:21.756957Z","shell.execute_reply.started":"2021-12-06T07:56:19.672884Z","shell.execute_reply":"2021-12-06T07:56:21.756181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_corr = df.corr() # Calculation of the correlation coefficients in pairs, with the default method:\n                    # Pearson, Standard Correlation Coefficient","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:56:21.759198Z","iopub.execute_input":"2021-12-06T07:56:21.759575Z","iopub.status.idle":"2021-12-06T07:56:22.557105Z","shell.execute_reply.started":"2021-12-06T07:56:21.759503Z","shell.execute_reply":"2021-12-06T07:56:22.556348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rank = df_corr['Class'] # Retrieving the correlation coefficients per feature in relation to the feature class\ndf_rank = pd.DataFrame(rank) \ndf_rank = np.abs(df_rank).sort_values(by='Class',ascending=False) # Ranking the absolute values of the coefficients\n                                                                  # in descending order\ndf_rank.dropna(inplace=True) # Removing Missing Data (not a number)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:56:22.558604Z","iopub.execute_input":"2021-12-06T07:56:22.559086Z","iopub.status.idle":"2021-12-06T07:56:22.566483Z","shell.execute_reply.started":"2021-12-06T07:56:22.559054Z","shell.execute_reply":"2021-12-06T07:56:22.565631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We seperate ours data in two groups : a train dataset and a test dataset\n\n# First we build our train dataset\ndf_train_all = df[0:150000] # We cut in two the original dataset\ndf_train_1 = df_train_all[df_train_all['Class'] == 1] # We seperate the data which are the frauds and the no frauds\ndf_train_0 = df_train_all[df_train_all['Class'] == 0]\nprint('In this dataset, we have ' + str(len(df_train_1)) +\" frauds so we need to take a similar number of non-fraud\")\n\ndf_sample=df_train_0.sample(300)\ndf_train = df_train_1.append(df_sample) # We gather the frauds with the no frauds. \ndf_train = df_train.sample(frac=1) # Then we mix our dataset","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:56:22.568371Z","iopub.execute_input":"2021-12-06T07:56:22.568618Z","iopub.status.idle":"2021-12-06T07:56:22.599821Z","shell.execute_reply.started":"2021-12-06T07:56:22.568591Z","shell.execute_reply":"2021-12-06T07:56:22.59832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = df_train.drop(['Time', 'Class'],axis=1) # We drop the features Time (useless), and the Class (label)\ny_train = df_train['Class'] # We create our label\nX_train = np.asarray(X_train)\ny_train = np.asarray(y_train)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:56:22.601155Z","iopub.execute_input":"2021-12-06T07:56:22.601359Z","iopub.status.idle":"2021-12-06T07:56:22.607318Z","shell.execute_reply.started":"2021-12-06T07:56:22.601334Z","shell.execute_reply":"2021-12-06T07:56:22.606483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"############################## with all the test dataset to see if the model learn correctly ##################\ndf_test_all = df[150000:]\n\nX_test_all = df_test_all.drop(['Time', 'Class'],axis=1)\ny_test_all = df_test_all['Class']\nX_test_all = np.asarray(X_test_all)\ny_test_all = np.asarray(y_test_all)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:56:22.608841Z","iopub.execute_input":"2021-12-06T07:56:22.60932Z","iopub.status.idle":"2021-12-06T07:56:22.632342Z","shell.execute_reply.started":"2021-12-06T07:56:22.609279Z","shell.execute_reply":"2021-12-06T07:56:22.63142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_rank = df_train[df_rank.index[1:11]] # We take the first ten ranked features\nX_train_rank = np.asarray(X_train_rank)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:56:22.63346Z","iopub.execute_input":"2021-12-06T07:56:22.633712Z","iopub.status.idle":"2021-12-06T07:56:22.638156Z","shell.execute_reply.started":"2021-12-06T07:56:22.633682Z","shell.execute_reply":"2021-12-06T07:56:22.637605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"############################## with all the test dataset to see if the model learn correctly ##################\nX_test_all_rank = df_test_all[df_rank.index[1:11]]\nX_test_all_rank = np.asarray(X_test_all_rank)\ny_test_all = np.asarray(y_test_all)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:56:22.638947Z","iopub.execute_input":"2021-12-06T07:56:22.639436Z","iopub.status.idle":"2021-12-06T07:56:22.660028Z","shell.execute_reply.started":"2021-12-06T07:56:22.639406Z","shell.execute_reply":"2021-12-06T07:56:22.658978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names=np.array(['0','1']) # Binary label, Class = 1 (fraud) and Class = 0 (no fraud)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:56:24.944847Z","iopub.execute_input":"2021-12-06T07:56:24.945427Z","iopub.status.idle":"2021-12-06T07:56:24.951931Z","shell.execute_reply.started":"2021-12-06T07:56:24.945389Z","shell.execute_reply":"2021-12-06T07:56:24.948891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to plot the confusion Matrix\ndef plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = 'd' \n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:56:25.717417Z","iopub.execute_input":"2021-12-06T07:56:25.718139Z","iopub.status.idle":"2021-12-06T07:56:25.726951Z","shell.execute_reply.started":"2021-12-06T07:56:25.71809Z","shell.execute_reply":"2021-12-06T07:56:25.725645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier = svm.SVC(kernel='linear') # We set a SVM classifier, the default SVM Classifier (Kernel = Radial Basis Function)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:56:29.594776Z","iopub.execute_input":"2021-12-06T07:56:29.595696Z","iopub.status.idle":"2021-12-06T07:56:29.599885Z","shell.execute_reply.started":"2021-12-06T07:56:29.595654Z","shell.execute_reply":"2021-12-06T07:56:29.599024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier.fit(X_train, y_train) # Then we train our model, with our balanced data train.","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:56:29.893187Z","iopub.execute_input":"2021-12-06T07:56:29.894196Z","iopub.status.idle":"2021-12-06T07:56:31.576307Z","shell.execute_reply.started":"2021-12-06T07:56:29.894138Z","shell.execute_reply":"2021-12-06T07:56:31.575427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_SVM_all = classifier.predict(X_test_all) #And finally, we predict our data test.","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:56:31.577658Z","iopub.execute_input":"2021-12-06T07:56:31.578034Z","iopub.status.idle":"2021-12-06T07:56:31.944577Z","shell.execute_reply.started":"2021-12-06T07:56:31.577993Z","shell.execute_reply":"2021-12-06T07:56:31.943635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test_all, prediction_SVM_all)\nplot_confusion_matrix(cm,class_names)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:56:31.945823Z","iopub.execute_input":"2021-12-06T07:56:31.946069Z","iopub.status.idle":"2021-12-06T07:56:32.297094Z","shell.execute_reply.started":"2021-12-06T07:56:31.94604Z","shell.execute_reply":"2021-12-06T07:56:32.296232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('We have detected ' + str(cm[1][1]) + ' frauds / ' + str(cm[1][1]+cm[1][0]) + ' total frauds.')\nprint('\\nSo, the probability to detect a fraud is ' + str(cm[1][1]/(cm[1][1]+cm[1][0])))\nprint(\"the accuracy is : \"+str((cm[0][0]+cm[1][1]) / (sum(cm[0]) + sum(cm[1]))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluating the classifier\n#printing every score of the classifier\n#scoring in any thing\nfrom sklearn.metrics import classification_report, accuracy_score,precision_score,recall_score,f1_score,matthews_corrcoef\nfrom sklearn.metrics import confusion_matrix\nprint(\"The model used is SVM\")\nacc= accuracy_score(prediction_SVM_all,y_test_all)\nprint(\"The accuracy is  {}\".format(acc))\nprec= precision_score(y_test_all,prediction_SVM_all)\nprint(\"The precision is {}\".format(prec))\nrec= recall_score(y_test_all,prediction_SVM_all)\nprint(\"The recall is {}\".format(rec))\nf1= f1_score(y_test_all,prediction_SVM_all)\nprint(\"The F1-Score is {}\".format(f1))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-06T08:01:02.80821Z","iopub.execute_input":"2021-12-06T08:01:02.808535Z","iopub.status.idle":"2021-12-06T08:01:02.937198Z","shell.execute_reply.started":"2021-12-06T08:01:02.808499Z","shell.execute_reply":"2021-12-06T08:01:02.936068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}